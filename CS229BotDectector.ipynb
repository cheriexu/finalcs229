{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS229BotDectector.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "bGcJCjeXFZbz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install pandas keras numpy xgboost sklearn nltk textblob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xPKnJCrwMivC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!free -h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lgs6YzPuFunI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iMwZVdN8h1tN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd drive/'My Drive'/CS229"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "convk9PYFt6p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Get genuine human tweets"
      ]
    },
    {
      "metadata": {
        "id": "Rya8yaGT_-Ht",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn import decomposition, ensemble\n",
        "\n",
        "import pandas as pd, xgboost, numpy as np, textblob, string\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import layers, models, optimizers\n",
        "\n",
        "real_users = pd.read_csv('./GenuineData/ga/users.csv',low_memory = False)\n",
        "real_tweets = pd.read_csv('./GenuineData/ga/tweets.csv',low_memory = False)\n",
        "real_df = real_tweets.merge(real_users, on='id',how = 'outer', suffixes = ('_tweets','_users')) #Merging the user and tweets\n",
        "real_df['labels']=pd.Series(np.ones(len(real_df['id']))) #Creating a new column to indicate that this is human data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TcyRaSYtsqwh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name() #We good using GPU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o-3RBOSS_fwp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "CANCELED: Get bot data to supplement class imbalance"
      ]
    },
    {
      "metadata": {
        "id": "kQEzdJPmzkIJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import Bot Dataset from this point on \n",
        "(https://github.com/fivethirtyeight/russian-troll-tweets/)"
      ]
    },
    {
      "metadata": {
        "id": "dwpQbQrvoAxw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "directory = os.fsencode('./russian-troll-tweets')\n",
        "troll_data = pd.DataFrame()\n",
        "for file in os.listdir(directory):\n",
        "  print(file)\n",
        "  filename = os.fsdecode(file)\n",
        "  if filename.endswith(\".csv\"):\n",
        "    botdata = pd.read_csv('./russian-troll-tweets/'+filename,low_memory = False)\n",
        "    troll_data = troll_data.append(botdata) #append together"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bdCjl1rEug7x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "frac = 80\n",
        "troll_data['labels']=pd.Series(np.zeros(len(botdata)))\n",
        "#Limiting too only English language tweets\n",
        "english_bot = troll_data[troll_data['language']  == 'English']\n",
        "troll_data['language'].unique()\n",
        "print(len(english_bot),len(troll_data)) #Class imbalance though, we need more spam bot results\n",
        "train_df = pd.DataFrame() #Create train data frame for splitting later\n",
        "train_df = train_df.append(real_df[['text','labels']].sample(int(len(real_df)/frac)))\n",
        "english_bot = english_bot.rename(index=str, columns={\"content\": \"text\"})\n",
        "train_df = train_df.append(english_bot[['text','labels']].sample(int(len(english_bot)/frac)))\n",
        "#Downsample use 10%\n",
        "len(train_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SGFE7ANbr2AE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#troll_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "plG4IxOc8OLd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Split train test dataset:"
      ]
    },
    {
      "metadata": {
        "id": "6qk21OCf8Nee",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# split the dataset into training and validation datasets \n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(train_df['text'], train_df['labels'], test_size = .2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "--xxycI-8Ufm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create Count Vectors for NB"
      ]
    },
    {
      "metadata": {
        "id": "RFT2IwTl8XHz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create CountVectorizer\n",
        "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
        "#fill in nan to make sklearn happy\n",
        "train_df['text'] = train_df['text'].fillna(' ')\n",
        "train_x = train_x.fillna(' ')\n",
        "valid_x = valid_x.fillna(' ') \n",
        "count_vect.fit(train_df['text'])\n",
        "# transform the training and validation data using count vectorizer object\n",
        "xtrain_count =  count_vect.transform(train_x)\n",
        "xvalid_count =  count_vect.transform(valid_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JBOfthG40QGc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(len(train_x),len(valid_x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H3WgYHt29Bf9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#xtrain_count.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_kIvH_xv3LOj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train Model of select type and make predictions. "
      ]
    },
    {
      "metadata": {
        "id": "VndDnk8G3Joq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
        "    classifier.fit(feature_vector_train, label)\n",
        "    pred_train = classifier.predict(feature_vector_train)\n",
        "    predictions = classifier.predict(feature_vector_valid)\n",
        "    if is_neural_net:\n",
        "        predictions = predictions.argmax(axis=-1)\n",
        "\n",
        "    return metrics.classification_report(label, pred_train), metrics.classification_report(valid_y, predictions)#confusion matrix on validation matrix\n",
        "  #metrics.confusion_matrix(label, pred_test), metrics.confusion_matrix(valid_y, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WPRaf6ws8nNE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Naive Bayes"
      ]
    },
    {
      "metadata": {
        "id": "Y3gHFXbN6j4w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.fit_transform(valid_y)\n",
        "valid_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hs8oEaeF8oLG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Naive Bayes on Count Vectors\n",
        "np.nan_to_num(xtrain_count)\n",
        "np.nan_to_num(xvalid_count)\n",
        "conf_test, conf_valid = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)\n",
        "print (conf_test[0:2])\n",
        "print(conf_valid[0:2])\n",
        "\n",
        "'''\n",
        "\n",
        "# Naive Bayes on Ngram Level TF IDF Vectors\n",
        "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
        "print \"NB, N-Gram Vectors: \", accuracy\n",
        "\n",
        "# Naive Bayes on Character Level TF IDF Vectors\n",
        "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6YNG6mAPtjUv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print (conf_test)\n",
        "print(conf_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xeveKrNAze8d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Naive Bayes on Count Vector Classification Results\n",
        "###         Train: n = 49596\n",
        "\n",
        "                  precision   recall  f1-score   support\n",
        "\n",
        "          0       0.90       0.91      0.90     20069\n",
        "          1       0.93      0.96      0.95     28448\n",
        "          \n",
        "          avg / total       0.90      0.92      0.91     49596\n",
        "          \n",
        "###          Valid: n = 12399\n",
        "  \n",
        "          \n",
        "           precision    recall  f1-score   support\n",
        "\n",
        "          0       0.83      0.85      0.84      5047\n",
        "          1       0.89      0.91      0.90      7087\n",
        "    avg / total       0.85      0.87      0.86     12399\n",
        "          \n",
        "          \n",
        "          \n",
        "          "
      ]
    },
    {
      "metadata": {
        "id": "CSJmGCm9qbo_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Word level tf-idf\n",
        "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
        "tfidf_vect.fit(train_df['text'])\n",
        "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
        "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
        "np.nan_to_num(xtrain_tfidf)\n",
        "np.nan_to_num(xvalid_tfidf)\n",
        "train, test = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4VebIMpy2ssk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes on Tf-iDF\n",
        "### Train: n = 49596\n",
        "    precision    recall  f1-score   support\n",
        "\n",
        "          0       0.85      0.78      0.81     20069\n",
        "          1       0.85      0.94      0.89     28448\n",
        "    avg / total       0.83      0.85      0.84     49596\n",
        "    \n",
        "###        Valid: n = 12399\n",
        "\n",
        "    precision    recall  f1-score   support\n",
        "\n",
        "          0       0.84      0.76      0.80      5047\n",
        "          1       0.84      0.93      0.88      7087\n",
        "       avg / total       0.82      0.84      0.83     12399"
      ]
    },
    {
      "metadata": {
        "id": "lMqCOMBtqX-n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GSXLQdj78eiF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ngram level tf-idf \n",
        "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "tfidf_vect_ngram.fit(trainDF['text'])\n",
        "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
        "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n",
        "\n",
        "# characters level tf-idf\n",
        "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "tfidf_vect_ngram_chars.fit(trainDF['text'])\n",
        "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
        "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}